{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023/2/27\n",
    "* rewrite tokenizer by hugging face\n",
    "* rewrite dataloader via yield and add key_padding_mask\n",
    "* Tying weight between embedding and pre_softmax\n",
    "* rewriting Transformer model via TransformerLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* add Label Smooth\n",
    "* rewrite train() and evaluate    almost cause by BatchLoader and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023/2/28\n",
    "* rewrite BatchLoader make the total batch_tokens <= max_len\n",
    "* merge valid_loader and train_loader to one function by argument dataset\n",
    "* writer translate function for test\n",
    "* carry BatchLoader in dataLoader of torch (by batch_size=1)\n",
    "* change de -> en to de<->en(intertranslation)\n",
    "* limited the max_len of output <= input length + 50\n",
    "* in evaluate function,delete the tokens following \\<eos>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023/3/14 update:\n",
    "* execute backward as soon as possible\n",
    "* checkpoint add valid BLEU score list(teacher forcing)\n",
    "* def autoregressive_evaluate method for calculating the bleu in the test environment\n",
    "* bleu*=100\n",
    "* add batch_tokens to hype-parameter\n",
    "* add gradient accumulation\n",
    "* checkpoint add valid BLEU score list(autoregressive)\n",
    "* warning fix:converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor.\n",
    "* save best_bleu parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future\n",
    "### Test module\n",
    "* beam search\n",
    "\n",
    "\n",
    "### Train module\n",
    "* use colossal-ai to train model (data parallel and gradient accumulation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/zrs/.conda/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "\n",
    "seed_value = 721\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value) \n",
    "torch.manual_seed(seed_value)    \n",
    "torch.cuda.manual_seed(seed_value)      \n",
    "# torch.cuda.manual_seed_all(seed_value)   \n",
    "\n",
    "torch.backends.cudnn.benchmark = False        # if benchmark=True, deterministic will be False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_tokens = 37000\n",
    "bos_id = 0\n",
    "eos_id = 1\n",
    "pad_id = 2\n",
    "\n",
    "# below two hypeparameter is not need\n",
    "# seq_len = 512\n",
    "# batch_size = 8\n",
    "\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "dff = 2048\n",
    "N = 6 # num of encoder/decoder layers\n",
    "p_drop = 0.1\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "gpu_num = 1\n",
    "warmup_steps = 4000*8//gpu_num\n",
    "\n",
    "truncate_len = 650\n",
    "batch_tokens = 1400 #  the maximum of the total num of src tokens + tgt tokens\n",
    "\n",
    "used_cuda = \"cuda:3\"\n",
    "device = torch.device(used_cuda if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "save_path = \"checkpoint.tar\"\n",
    "\n",
    "# other parameter in train() and spm.SentencePieceTrainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-17T12:09:59.376655Z",
     "iopub.status.busy": "2023-02-17T12:09:59.374968Z",
     "iopub.status.idle": "2023-02-17T12:25:08.578162Z",
     "shell.execute_reply": "2023-02-17T12:25:08.576340Z",
     "shell.execute_reply.started": "2023-02-17T12:09:59.376508Z"
    }
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"wmt14\", 'de-en', split='train')\n",
    "\n",
    "# with open(\"en.txt\",'w') as f:\n",
    "#     for i in range(len(dataset)):\n",
    "#         f.write(dataset[i]['translation']['en']+'\\n')\n",
    "        \n",
    "# with open(\"de.txt\",'w') as f:\n",
    "#     for i in range(len(dataset)):\n",
    "#         f.write(dataset[i]['translation']['de']+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:25:08.581937Z",
     "iopub.status.busy": "2023-02-17T12:25:08.581441Z",
     "iopub.status.idle": "2023-02-17T12:25:08.588636Z",
     "shell.execute_reply": "2023-02-17T12:25:08.587034Z",
     "shell.execute_reply.started": "2023-02-17T12:25:08.581891Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.save_to_disk('dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset to memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### truncate the long sentence (though we can train transformer by any length ,the gpu memory cannot allow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:25:08.590772Z",
     "iopub.status.busy": "2023-02-17T12:25:08.590310Z",
     "iopub.status.idle": "2023-02-17T12:25:08.603615Z",
     "shell.execute_reply": "2023-02-17T12:25:08.602749Z",
     "shell.execute_reply.started": "2023-02-17T12:25:08.590725Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('dataset')\n",
    "\n",
    "de_en_pairs = []\n",
    "for i in range(len(dataset)):        \n",
    "    de_en_pairs.append((dataset[i]['translation']['de'][:truncate_len],dataset[i]['translation']['en'][:truncate_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_en_pairs = sorted(de_en_pairs,key=lambda x:+len(x[0])+len(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(de_en_pairs[-1][0])+len(de_en_pairs[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(de_en_pairs[-500][0])+len(de_en_pairs[-500][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_en_pairs = de_en_pairs[:-500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_en_pairs[-1][0])+len(de_en_pairs[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(de_en_pairs[0][0])+len(de_en_pairs[0][1]))\n",
    "# print(len(de_en_pairs[1500][0])+len(de_en_pairs[1500][1]))\n",
    "# de_en_pairs = de_en_pairs[1500:]\n",
    "# print(len(de_en_pairs[0][0])+len(de_en_pairs[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid Dataloader  input:[S,B],mask:[B,S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt14 (/data2/zrs/.cache/huggingface/datasets/wmt14/de-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "valid_dataset = load_dataset(\"wmt14\", 'de-en', split='validation')\n",
    "\n",
    "valid_de_en_pairs = []\n",
    "for i in range(len(valid_dataset)):\n",
    "    valid_de_en_pairs.append((valid_dataset[i]['translation']['de'],valid_dataset[i]['translation']['en']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchloader input:[S,B],mask:[B,S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "def batch_generator(dataset,gpu_num=1,max_len=batch_tokens):\n",
    "    en_cnt = 0\n",
    "    de_cnt = 0\n",
    "    en_batch = []\n",
    "    de_batch = []\n",
    "    batch_size = 0\n",
    "    for pairs in dataset:\n",
    "        \n",
    "        en_batch.append(pairs[1])\n",
    "        de_batch.append(pairs[0])\n",
    "        en_cnt += len(pairs[1])\n",
    "        de_cnt += len(pairs[0])\n",
    "        batch_size += 1\n",
    "        \n",
    "        if batch_size%gpu_num == 0:          \n",
    "            if en_cnt + de_cnt > max_len*gpu_num:\n",
    "\n",
    "                en_output = tokenizer.encode_batch(en_batch[:-gpu_num])\n",
    "                de_output = tokenizer.encode_batch(de_batch[:-gpu_num])\n",
    "                \n",
    "                \n",
    "                en_ids = [] \n",
    "                de_ids = []\n",
    "                target_en_ids = []\n",
    "                target_de_ids = []\n",
    "                en_padding_mask = []\n",
    "                de_padding_mask = []\n",
    "\n",
    "                for en in en_output:\n",
    "                    en_ids.append(en.ids)\n",
    "                    target_en_ids.append(en.ids[1:]+[pad_id])\n",
    "                    en_padding_mask.append(en.attention_mask)\n",
    "                    \n",
    "                for de in de_output:\n",
    "                    de_ids.append(de.ids)\n",
    "                    target_de_ids.append(de.ids[1:]+[pad_id])\n",
    "                    de_padding_mask.append(de.attention_mask)              \n",
    "\n",
    "                yield torch.LongTensor(en_ids).t().contiguous(),\\\n",
    "                        torch.LongTensor(de_ids).t().contiguous(),\\\n",
    "                        torch.LongTensor(target_en_ids).t().contiguous(),\\\n",
    "                        torch.LongTensor(target_de_ids).t().contiguous(),\\\n",
    "                        torch.BoolTensor(1-np.array(en_padding_mask)),\\\n",
    "                        torch.BoolTensor(1-np.array(de_padding_mask))\n",
    "            \n",
    "\n",
    "                en_cnt = 0\n",
    "                de_cnt = 0            \n",
    "                en_batch = en_batch[-gpu_num:]\n",
    "                de_batch = de_batch[-gpu_num:]            \n",
    "\n",
    "    if en_ids:\n",
    "        yield torch.LongTensor(en_ids).t().contiguous(),\\\n",
    "                torch.LongTensor(de_ids).t().contiguous(),\\\n",
    "                torch.LongTensor(target_en_ids).t().contiguous(),\\\n",
    "                torch.LongTensor(target_de_ids).t().contiguous(),\\\n",
    "                torch.BoolTensor(1-np.array(en_padding_mask)),\\\n",
    "                torch.BoolTensor(1-np.array(de_padding_mask))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class FoodDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.data = dataset\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        example = self.data[index]\n",
    "        return example[0],example[1],example[2],example[3],example[4],example[5]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [batch for batch in batch_generator(dataset=de_en_pairs,gpu_num=gpu_num)]\n",
    "valid_list = [batch for batch in batch_generator(dataset=valid_de_en_pairs,gpu_num=gpu_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FoodDataset(train_list)\n",
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
    "\n",
    "valid_dataset = FoodDataset(valid_list)\n",
    "valid_loader=torch.utils.data.DataLoader(valid_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch Transfomer(by Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:43.172152Z",
     "iopub.status.busy": "2023-02-17T12:57:43.171584Z",
     "iopub.status.idle": "2023-02-17T12:57:43.185476Z",
     "shell.execute_reply": "2023-02-17T12:57:43.183864Z",
     "shell.execute_reply.started": "2023-02-17T12:57:43.172119Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoderLayer, TransformerDecoderLayer\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = p_drop, max_len: int = 40000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation, encoder key padding_mask and decoder key padding mask differnt with paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:43.188067Z",
     "iopub.status.busy": "2023-02-17T12:57:43.187619Z",
     "iopub.status.idle": "2023-02-17T12:57:43.199421Z",
     "shell.execute_reply": "2023-02-17T12:57:43.197937Z",
     "shell.execute_reply.started": "2023-02-17T12:57:43.188025Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self,ntoken=n_tokens,d_model=d_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.emb = nn.Embedding(ntoken,d_model,padding_idx=pad_id)\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(d_model=d_model,nhead=nhead,dim_feedforward=dff,\n",
    "                                               dropout=p_drop,activation='gelu')\n",
    "        self.encoder = TransformerEncoder(encoder_layer,N)\n",
    "        \n",
    "        decoder_layer = TransformerDecoderLayer(d_model=d_model,nhead=nhead,dim_feedforward=dff,\n",
    "                                               dropout=p_drop,activation='gelu')\n",
    "        self.decoder = TransformerDecoder(decoder_layer,N)\n",
    "    \n",
    "    def forward(self,src,tgt,tgt_mask,src_key_padding_mask,tgt_key_padding_mask):\n",
    "        # src:[S,B] tgt:[T,B] tgt_mask:[T,T] src_key_padding_mask:[N,S] tgt_key_padding_mask:[N,T]\n",
    "        # E=d_model\n",
    "        src_emb = self.emb(src)*math.sqrt(self.d_model)  #src:[S,B] -> src_emb:[S,B,E]\n",
    "        tgt_emb = self.emb(tgt)*math.sqrt(self.d_model)  #tgt:[T,B] -> tgt_emb:[T,B,E]\n",
    "        src_emb = self.pos_encoding(src_emb)\n",
    "        tgt_emb = self.pos_encoding(tgt_emb)\n",
    "        \n",
    "        # emb = embedding*sqrt(d_model) + PosEmbedding : [S,B,E]\n",
    "        # tgt_mask:[T,T]\n",
    "        \n",
    "        src_hidden = self.encoder(src_emb, src_key_padding_mask=src_key_padding_mask) #[S,B,E]\n",
    "        \n",
    "        tgt_hidden = self.decoder(tgt_emb,src_hidden,tgt_mask=tgt_mask,\\\n",
    "                                  memory_key_padding_mask=src_key_padding_mask,\\\n",
    "                                  tgt_key_padding_mask=tgt_key_padding_mask) #[T,B,E]\n",
    "                                 \n",
    "        \n",
    "        return F.linear(tgt_hidden,self.emb.weight) # Tying Weight [T,B,ntokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "* de->en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:43.202058Z",
     "iopub.status.busy": "2023-02-17T12:57:43.201558Z",
     "iopub.status.idle": "2023-02-17T12:57:43.852498Z",
     "shell.execute_reply": "2023-02-17T12:57:43.851312Z",
     "shell.execute_reply.started": "2023-02-17T12:57:43.202017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (emb): Embedding(37000, 512, padding_idx=2)\n",
      "  (pos_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id,label_smoothing=epsilon) # Label Smooth\n",
    "transformer_model = TransformerModel()\n",
    "transformer_model.to(device)\n",
    "print(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:43.854607Z",
     "iopub.status.busy": "2023-02-17T12:57:43.854166Z",
     "iopub.status.idle": "2023-02-17T12:57:43.861068Z",
     "shell.execute_reply": "2023-02-17T12:57:43.859090Z",
     "shell.execute_reply.started": "2023-02-17T12:57:43.854571Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     optimizer.step()\n",
    "#     scheduler.step()\n",
    "#     print(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:43.863383Z",
     "iopub.status.busy": "2023-02-17T12:57:43.862992Z",
     "iopub.status.idle": "2023-02-17T12:57:43.872194Z",
     "shell.execute_reply": "2023-02-17T12:57:43.871193Z",
     "shell.execute_reply.started": "2023-02-17T12:57:43.863349Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install fvcore -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:43.875779Z",
     "iopub.status.busy": "2023-02-17T12:57:43.874243Z",
     "iopub.status.idle": "2023-02-17T12:57:43.886037Z",
     "shell.execute_reply": "2023-02-17T12:57:43.885175Z",
     "shell.execute_reply.started": "2023-02-17T12:57:43.875724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                | #elements or shape   |\n",
      "|:--------------------|:---------------------|\n",
      "| model               | 63.1M                |\n",
      "|  emb                |  18.9M               |\n",
      "|   emb.weight        |   (37000, 512)       |\n",
      "|  encoder            |  18.9M               |\n",
      "|   encoder.layers    |   18.9M              |\n",
      "|    encoder.layers.0 |    3.2M              |\n",
      "|    encoder.layers.1 |    3.2M              |\n",
      "|    encoder.layers.2 |    3.2M              |\n",
      "|    encoder.layers.3 |    3.2M              |\n",
      "|    encoder.layers.4 |    3.2M              |\n",
      "|    encoder.layers.5 |    3.2M              |\n",
      "|  decoder            |  25.2M               |\n",
      "|   decoder.layers    |   25.2M              |\n",
      "|    decoder.layers.0 |    4.2M              |\n",
      "|    decoder.layers.1 |    4.2M              |\n",
      "|    decoder.layers.2 |    4.2M              |\n",
      "|    decoder.layers.3 |    4.2M              |\n",
      "|    decoder.layers.4 |    4.2M              |\n",
      "|    decoder.layers.5 |    4.2M              |\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "print(parameter_count_table(transformer_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(path,\n",
    "                    epoch,\n",
    "                    modules,\n",
    "                    optimizers,\n",
    "                    schedulers,\n",
    "                    step_list,\n",
    "                    train_loss_list,\n",
    "                    val_loss_list,\n",
    "                    val_bleu_list,\n",
    "                    val_auto_bleu_list,\n",
    "                    safe_replacement: bool = True):\n",
    "\n",
    "    if isinstance(modules, torch.nn.Module):\n",
    "        modules = [modules]\n",
    "    if isinstance(optimizers, torch.optim.Optimizer):\n",
    "        optimizers = [optimizers]\n",
    "    if not isinstance(schedulers, list):\n",
    "        schedulers = [schedulers]\n",
    "    # Data dictionary to be saved\n",
    "    data = {\n",
    "        'epoch': epoch,\n",
    "        # Current time (UNIX timestamp)\n",
    "        'time': time.time(),\n",
    "        # State dict for all the modules\n",
    "        'modules': [m.state_dict() for m in modules],\n",
    "        # State dict for all the optimizers\n",
    "        'optimizers': [o.state_dict() for o in optimizers],\n",
    "        'schedulers': [s.state_dict() for s in schedulers],\n",
    "        \"step_list\":step_list,\n",
    "        \"train_loss_list\":train_loss_list,\n",
    "        \"val_loss_list\":val_loss_list,\n",
    "        \"val_bleu_list\":val_bleu_list,\n",
    "        \"val_auto_bleu_list\":val_auto_bleu_list\n",
    "    }\n",
    "\n",
    "    # Safe replacement of old checkpoint\n",
    "\n",
    "    if os.path.exists(path) and safe_replacement:\n",
    "        # There's an old checkpoint. Rename it!\n",
    "        temp_file = path + '.old'\n",
    "        abandon_file = path + '.abandon'\n",
    "        \n",
    "        if os.path.exists(temp_file):\n",
    "            os.rename(temp_file,abandon_file)\n",
    "        \n",
    "        os.rename(path, temp_file)\n",
    "        \n",
    "        if os.path.exists(abandon_file):\n",
    "            os.unlink(abandon_file)\n",
    "        \n",
    "        \n",
    "\n",
    "    # Save the new checkpoint\n",
    "    with open(path, 'wb') as fp:\n",
    "        torch.save(data, fp)\n",
    "        # Flush and sync the FS\n",
    "        fp.flush()\n",
    "        os.fsync(fp.fileno())\n",
    "\n",
    "    print(\"save to \",path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def load_checkpoint(path,\n",
    "                    default_epoch,\n",
    "                    modules,\n",
    "                    optimizers,\n",
    "                    schedulers,\n",
    "                    step_list,\n",
    "                    train_loss_list,\n",
    "                    val_loss_list,\n",
    "                    val_bleu_list,\n",
    "                    val_auto_bleu_list,\n",
    "                    verbose: bool = True):\n",
    "\n",
    "    if isinstance(modules, torch.nn.Module):\n",
    "        modules = [modules]\n",
    "    if isinstance(optimizers, torch.optim.Optimizer):\n",
    "        optimizers = [optimizers]\n",
    "    if not isinstance(schedulers, list):\n",
    "        schedulers = [schedulers]\n",
    "        \n",
    "    # If there's a checkpoint\n",
    "    if os.path.exists(path):\n",
    "        # Load data\n",
    "        data = torch.load(path, map_location=next(modules[0].parameters()).device)\n",
    "\n",
    "        # Inform the user that we are loading the checkpoint\n",
    "        if verbose:\n",
    "            print(f\"Loaded checkpoint saved at {datetime.fromtimestamp(data['time']).strftime('%Y-%m-%d %H:%M:%S')}. \"\n",
    "                  f\"Resuming from epoch {data['epoch']}\")\n",
    "\n",
    "        # Load state for all the modules\n",
    "        for i, m in enumerate(modules):\n",
    "            modules[i].load_state_dict(data['modules'][i])\n",
    "\n",
    "        # Load state for all the optimizers\n",
    "        for i, o in enumerate(optimizers):\n",
    "            optimizers[i].load_state_dict(data['optimizers'][i])\n",
    "\n",
    "        for i, s in enumerate(schedulers):\n",
    "            schedulers[i].load_state_dict(data['schedulers'][i])\n",
    "            \n",
    "        step_list.clear()\n",
    "        step_list += data['step_list']\n",
    "        \n",
    "        train_loss_list.clear()\n",
    "        train_loss_list += data['train_loss_list']        \n",
    "        \n",
    "        val_loss_list.clear()\n",
    "        val_loss_list += data['val_loss_list']\n",
    "        \n",
    "        val_bleu_list.clear()\n",
    "        val_bleu_list += data['val_bleu_list']\n",
    "        \n",
    "        val_auto_bleu_list.clear()\n",
    "        val_auto_bleu_list += data['val_auto_bleu_list']\n",
    "        \n",
    "        # Next epoch\n",
    "        return data['epoch'] + 1\n",
    "    else:\n",
    "        return default_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (train de<=>en i.e intertranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int):\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = generate_square_subsequent_mask(38481) #38481 is the max_len  occur too much memory \n",
    "# mask = mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:43.888380Z",
     "iopub.status.busy": "2023-02-17T12:57:43.887928Z",
     "iopub.status.idle": "2023-02-17T12:57:43.906996Z",
     "shell.execute_reply": "2023-02-17T12:57:43.905341Z",
     "shell.execute_reply.started": "2023-02-17T12:57:43.888328Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def train(model,epoch):\n",
    "    \n",
    "    \n",
    "    lambda1 = lambda step_num: min((step_num+1)**(-0.5),(step_num+1)*(warmup_steps**(-1.5)))\n",
    "    optimizer = torch.optim.Adam(transformer_model.parameters(),lr=d_model**(-0.5),betas=(0.9,0.98),eps=1e-9)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    val_bleu_list = []\n",
    "    val_auto_bleu_list = []\n",
    "    step_list = []    \n",
    "\n",
    "    steps = 0\n",
    "    best_bleu = 0\n",
    "    \n",
    "    load_checkpoint(path=save_path,\n",
    "                    default_epoch=epoch,\n",
    "                    modules=model,\n",
    "                    optimizers=optimizer,\n",
    "                    schedulers=scheduler,\n",
    "                    step_list=step_list,\n",
    "                    train_loss_list=loss_list,\n",
    "                    val_loss_list=val_loss_list,\n",
    "                    val_bleu_list=val_bleu_list,\n",
    "                    val_auto_bleu_list=val_auto_bleu_list)\n",
    "                   \n",
    "    if step_list:\n",
    "        steps = step_list[-1]\n",
    "        \n",
    "    if val_auto_bleu_list:\n",
    "        best_bleu = max(val_auto_bleu_list)\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    log_interval = 50000\n",
    "    start_time = time.time()\n",
    "\n",
    "    accumulation_steps = (25000*2)//batch_tokens\n",
    "    optimizer.zero_grad()\n",
    "    for en_ids,de_ids,target_en_ids,target_de_ids,\\\n",
    "        en_padding_mask,de_padding_mask in train_loader:\n",
    "\n",
    "        en_ids = en_ids.squeeze().to(device)\n",
    "        de_ids = de_ids.squeeze().to(device)\n",
    "        target_en_ids = target_en_ids.squeeze().to(device)\n",
    "        target_de_ids = target_de_ids.squeeze().to(device)\n",
    "        en_padding_mask = en_padding_mask.squeeze().to(device)\n",
    "        de_padding_mask = de_padding_mask.squeeze().to(device)\n",
    "        \n",
    "#         print(en_ids.shape,de_ids.shape,en_padding_mask.shape)\n",
    "        # en_ids:[T,B],de_ids:[S,B],target_en_ids:[T,B],target_de_ids:[S,B]\n",
    "        # en_padding_mask:[B,T] de_padding_mask:[B,S]\n",
    "        \n",
    "        # mask_slide:[T,T]\n",
    "        #target_de_ids:$de<eos> en_ids:<bos>$en<eos>\n",
    "#         output = model(target_de_ids,en_ids,mask[:en_ids.shape[0]][:en_ids.shape[0]])\n",
    "\n",
    "\n",
    "        # de -> en\n",
    "        #de_ids:$<bos>de<eos> en_ids:<bos>$en<eos>\n",
    "        output = model(de_ids,en_ids,\\\n",
    "                       generate_square_subsequent_mask(en_ids.shape[0]).to(device),\\\n",
    "                       de_padding_mask,en_padding_mask)\n",
    "                       \n",
    "        # output:[T,B,ntokens]\n",
    "\n",
    "        loss = 0.5*criterion(output.view(-1,n_tokens),target_en_ids.view(-1))\n",
    "        total_loss += loss.item()\n",
    "        loss = loss/accumulation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        output = model(en_ids,de_ids,\\\n",
    "                       generate_square_subsequent_mask(de_ids.shape[0]).to(device),\\\n",
    "                       en_padding_mask,de_padding_mask)\n",
    "                       \n",
    "\n",
    "        loss = 0.5*criterion(output.view(-1,n_tokens),target_de_ids.view(-1))\n",
    "        total_loss += loss.item()\n",
    "        loss = loss/accumulation_steps        \n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        \n",
    "        steps += 1\n",
    "        if steps%accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "\n",
    "        if steps%log_interval == 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            s_per_step = (time.time() - start_time) / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| steps {steps:5d}|'\n",
    "                  f'lr {lr} | s/step {s_per_step:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            loss_list.append(cur_loss)\n",
    "            step_list.append(steps)\n",
    "            \n",
    "            val_loss_list_e, val_bleu_list_e = evaluate(model,valid_loader)\n",
    "            val_loss_list.append(val_loss_list_e)\n",
    "            val_bleu_list.append(val_bleu_list_e)\n",
    "            \n",
    "            val_auto_bleu_list_e = autoregressive_evaluate(model,valid_de_en_pairs)\n",
    "            val_auto_bleu_list.append(val_auto_bleu_list_e)\n",
    "            \n",
    "            if val_auto_bleu_list_e>best_bleu:\n",
    "                best_bleu = val_auto_bleu_list_e\n",
    "                print(\"best autoregressive bleu score:\",best_bleu)\n",
    "                torch.save(model.state_dict(),\"best_bleu.pt\")\n",
    "                print(\"save to best_bleu.pt\")\n",
    "            \n",
    "            \n",
    "            save_checkpoint(path=save_path,\n",
    "                    epoch=epoch,\n",
    "                    modules=model,\n",
    "                    optimizers=optimizer,\n",
    "                    schedulers=scheduler,\n",
    "                    step_list=step_list,\n",
    "                    train_loss_list=loss_list,\n",
    "                    val_loss_list=val_loss_list,\n",
    "                    val_bleu_list=val_bleu_list,\n",
    "                    val_auto_bleu_list=val_auto_bleu_list)\n",
    "                        \n",
    "                    \n",
    "\n",
    "    save_checkpoint(path=save_path,\n",
    "            epoch=epoch,\n",
    "            modules=model,\n",
    "            optimizers=optimizer,\n",
    "            schedulers=scheduler,\n",
    "            step_list=step_list,\n",
    "            train_loss_list=loss_list,\n",
    "            val_loss_list=val_loss_list,\n",
    "            val_bleu_list=val_bleu_list,\n",
    "            val_auto_bleu_list=val_auto_bleu_list)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate (only test de->en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:46.461572Z",
     "iopub.status.busy": "2023-02-17T12:57:46.460368Z",
     "iopub.status.idle": "2023-02-17T12:57:46.603425Z",
     "shell.execute_reply": "2023-02-17T12:57:46.602446Z",
     "shell.execute_reply.started": "2023-02-17T12:57:46.461515Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def evaluate(model, valid_loader):\n",
    "    print('='*30)\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    cnt=0\n",
    "    pred_token_list = []\n",
    "    en_token_list = []   \n",
    "    \n",
    "    flag = 1\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for en_ids,de_ids,target_en_ids,target_de_ids,\\\n",
    "            en_padding_mask,de_padding_mask in valid_loader:\n",
    "            \n",
    "            en_ids = en_ids.squeeze().to(device)\n",
    "            de_ids = de_ids.squeeze().to(device)\n",
    "            target_en_ids = target_en_ids.squeeze().to(device)\n",
    "            target_de_ids = target_de_ids.squeeze().to(device)\n",
    "            en_padding_mask = en_padding_mask.squeeze().to(device)\n",
    "            de_padding_mask = de_padding_mask.squeeze().to(device)\n",
    "\n",
    "            \n",
    "            # en_ids:[T,B],de_ids:[S,B],target_en_ids:[T,B],target_de_ids:[S,B]\n",
    "            # en_padding_mask:[B,T] de_padding_mask:[B,S]\n",
    "\n",
    "            # mask_slide:[T,T]\n",
    "            #target_de_ids:$de<eos> en_ids:<bos>$en<eos>\n",
    "    #         output = model(target_de_ids,en_ids,mask[:en_ids.shape[0]][:en_ids.shape[0]])\n",
    "\n",
    "    \n",
    "            # de -> en\n",
    "            #de_ids:$<bos>de<eos> en_ids:<bos>$en<eos>\n",
    "            output = model(de_ids,en_ids,\\\n",
    "                           generate_square_subsequent_mask(en_ids.shape[0]).to(device),\\\n",
    "                           de_padding_mask,en_padding_mask)\n",
    "\n",
    "            # output:[T,B,ntokens]\n",
    "            # target_en_ids:[T,B]\n",
    "\n",
    "            loss = criterion(output.view(-1,n_tokens),target_en_ids.view(-1))\n",
    "        \n",
    "            \n",
    "            total_loss += en_ids.shape[1]*loss.item() #B*mean_loss\n",
    "            cnt += en_ids.shape[1]\n",
    "            \n",
    "            pred = torch.argmax(output,dim=-1)\n",
    "            # pred[T,B]  target_en_ids[T,B]  tokens_id\n",
    "            \n",
    "            pred = pred.t()\n",
    "            target_en_ids = target_en_ids.t()\n",
    "            # pred[B,T]  target_en_ids[B,T]  tokens_id            \n",
    "            \n",
    "            \n",
    "            sents = tokenizer.decode_batch(pred.tolist())\n",
    "            #[B,T(id)] ->[B(str)] \n",
    "            if flag:\n",
    "                print(sents[0])\n",
    "            \n",
    "    \n",
    "            pred_output = tokenizer.encode_batch(sents)\n",
    "            for o in pred_output:\n",
    "                #o.tokens :[T(str)]\n",
    "                \n",
    "                token_list = []\n",
    "                for token in o.tokens:\n",
    "                    if token == eos_id:\n",
    "                        break\n",
    "                    token_list.append(token)\n",
    "                pred_token_list.append(token_list)\n",
    "                # pred_token_list [allB,T(str)]\n",
    "            \n",
    "            true_sents = tokenizer.decode_batch(target_en_ids.tolist())\n",
    "            #[B,T(id)] -> [B(str)] \n",
    "            if flag:\n",
    "                print(true_sents[0])\n",
    "                flag=0\n",
    "            \n",
    "            \n",
    "            target_output = tokenizer.encode_batch(true_sents) \n",
    "            for o in target_output:\n",
    "                #o.tokens :[T(str)]\n",
    "                en_token_list.append([o.tokens])\n",
    "                # en_token_list [allB,1,T(str)]\n",
    "            \n",
    "    \n",
    "    avg_loss = total_loss/cnt\n",
    "    print(f\"valid_loss:{avg_loss:.5f}\")\n",
    "    \n",
    "#     print(len(pred_token_list),len(en_token_list))\n",
    "    bleu = bleu_score(pred_token_list,en_token_list)*100\n",
    "    print(f\"teacher forcing bleu:{bleu}\")\n",
    "    \n",
    "#     # pred_token_list [allB,T(str)] # en_token_list [allB,1,T(str)]\n",
    "#     print(pred_token_list[0][:20],en_token_list[0])\n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "    return avg_loss, bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autoregressive translate( de -> en )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src, references):\n",
    "    # src:str\n",
    "    output = tokenizer.encode(src)\n",
    "    \n",
    "    src_ids = [output.ids] #[1,S] \n",
    "    src_padding_mask = np.array([1-np.array(output.attention_mask)]) #[1,S]\n",
    "    tgt_ids = [[bos_id]] #[1,1] i.e [1,T]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while tgt_ids[0][-1] != eos_id:\n",
    "            if len(tgt_ids[0]) > len(output.ids) +50:\n",
    "                break\n",
    "            pred = model(torch.LongTensor(src_ids).t().contiguous().to(device),\n",
    "                                    torch.LongTensor(tgt_ids).t().contiguous().to(device),\n",
    "                                    generate_square_subsequent_mask(len(tgt_ids[0])).to(device),\n",
    "                                    torch.LongTensor(src_padding_mask).to(device),None)\n",
    "            # [T,1,ntokens]\n",
    "\n",
    "            next_token = pred.argmax(dim=-1)[-1]\n",
    "            #                      [T,1]\n",
    "\n",
    "            # tgt_ids :<bos>       A         :[T]\n",
    "            # pred    :  A    <next token>   :[T]\n",
    "\n",
    "            tgt_ids[0].append(next_token.item())\n",
    "            # tgt_ids:[1,T]->[1,T+1]\n",
    "            \n",
    "    # tgt_ids:[1,T], tgt_ids[0]:[T]\n",
    "    tgt = tokenizer.decode(tgt_ids[0])\n",
    "#     print(\"\\nsrc:\",src)\n",
    "#     print(\"\\npred:\",tgt)\n",
    "    \n",
    "    output = tokenizer.encode(tgt)\n",
    "    candidate = [output.tokens] #  candidate [allB(1),T(str)] # references [allB(1),1,T(str)]\n",
    "    bleu = bleu_score(candidate,references)*100\n",
    "#     print(f\"\\nbleu:{bleu}\")\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autoregressive evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def autoregressive_evaluate(model, pairs):\n",
    "    print('='*30)\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    \n",
    "\n",
    "    total_bleu = 0.0\n",
    "#     print(\"num of valid sample:\",len(pairs))\n",
    "    for i in range(len(pairs)):\n",
    "    #     print(\"=\"*40)\n",
    "#         print(i)\n",
    "        output = tokenizer.encode(pairs[i][1])\n",
    "        total_bleu += translate(model,pairs[i][0],references=[[output.tokens]])  # references [allB(1),1,T(str)]  \n",
    "    \n",
    "    avg_bleu = total_bleu/len(pairs)\n",
    "    print(\"autoregressive bleu:\",avg_bleu)\n",
    "    \n",
    "    model.train()\n",
    "    return avg_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Training here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T12:57:46.606409Z",
     "iopub.status.busy": "2023-02-17T12:57:46.604991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps    20|lr 7.720404443770458e-09 | s/step  0.08 | loss 99.43 | ppl 15139873522580631824528340517021288815919104.00\n",
      "==============================\n",
      "nehmlichkeiteniformnehmlichkeitennehmlichkeitennehmlichkeitennehmlichkeiteniformnehmlichkeitennehmlichkeiten-nehmlichkeitennehmlichkeitenierens Obama nächsten nächsten nächsten nächsten Grundsiformiformiformiformiformiformiform nächsteniformiformiformiformiformnehmlichkeitennehmlichkeitennehmlichkeiten\n",
      " A Republican strategy to counter the re-election of Obama\n",
      "valid_loss:100.76843\n",
      "teacher forcing bleu:21.667484939098358\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    train(transformer_model,epoch=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
